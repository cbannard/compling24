{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3946b723",
      "metadata": {
        "id": "3946b723"
      },
      "source": [
        "# LELA32052 Computational Linguistics Week 9\n",
        "\n",
        "This week we are going to take a look at part of speech tagging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a56a86",
      "metadata": {
        "id": "96a56a86"
      },
      "source": [
        "## Tagged corpora\n",
        "In looking to understand part of speech tagging, it is useful to start by looking at some human (rather than machine) tagged data. NLTK contains a number of corpora. We can import a few of these as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14cae1f9",
      "metadata": {
        "id": "14cae1f9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "nltk.download('sinica_treebank')\n",
        "nltk.download('indian')\n",
        "nltk.download('conll2002')\n",
        "nltk.download('cess_cat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692f918a",
      "metadata": {
        "id": "692f918a"
      },
      "outputs": [],
      "source": [
        "brown.tagged_words()[1:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af0308ad",
      "metadata": {
        "id": "af0308ad"
      },
      "outputs": [],
      "source": [
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe6114d",
      "metadata": {
        "id": "abe6114d"
      },
      "outputs": [],
      "source": [
        "brown.tagged_words(tagset=\"universal\")[1:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1be8f20",
      "metadata": {
        "id": "f1be8f20"
      },
      "outputs": [],
      "source": [
        "nltk.corpus.sinica_treebank.tagged_words() # Chinese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77905320",
      "metadata": {
        "id": "77905320"
      },
      "outputs": [],
      "source": [
        "nltk.corpus.indian.tagged_words() # Bangla, Hindi, Marathi, and Telugu language data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e04ece",
      "metadata": {
        "id": "25e04ece"
      },
      "outputs": [],
      "source": [
        "nltk.corpus.conll2002.tagged_words() # Spanish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c03845",
      "metadata": {
        "id": "56c03845"
      },
      "outputs": [],
      "source": [
        "nltk.corpus.cess_cat.tagged_words() # Catalan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778e55a5",
      "metadata": {
        "id": "778e55a5"
      },
      "source": [
        "## Inspecting tagged corpora\n",
        "\n",
        "Inspecting human tagged corpora can be useful for both linguistic research and for building taggers. We can use the NLTK toolkit to do this.\n",
        "\n",
        "Most straightforwardly we can look at the frequency with which particular words are given a tag (we will return to this later when we come to build a tagger)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2930d972-3ac9-42b6-9c95-54b913a9ccd5",
      "metadata": {
        "id": "2930d972-3ac9-42b6-9c95-54b913a9ccd5"
      },
      "outputs": [],
      "source": [
        "sent = [(\"the\",\"DET\"),(\"man\",\"NOUN\"),(\"walked\",\"VERB\"),(\"the\",\"DET\"),(\"dog\",\"NOUN\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab8f8e9",
      "metadata": {
        "id": "0ab8f8e9"
      },
      "outputs": [],
      "source": [
        "cfd1 = nltk.ConditionalFreqDist(sent)\n",
        "cfd1['the']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b97e58",
      "metadata": {
        "id": "65b97e58"
      },
      "source": [
        "When we apply this to whole corpora, it becomes useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ffeff5",
      "metadata": {
        "id": "88ffeff5"
      },
      "outputs": [],
      "source": [
        "brown_tagged = brown.tagged_words(tagset='universal')\n",
        "cfd1 = nltk.ConditionalFreqDist(brown_tagged)\n",
        "cfd1['the']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd1['run']"
      ],
      "metadata": {
        "id": "_hW-I4pSvQmK"
      },
      "id": "_hW-I4pSvQmK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94cf95d7",
      "metadata": {
        "id": "94cf95d7"
      },
      "source": [
        "And if we additionally use a couple of other NLTK tools (which we don't have time to cover in detail - I just want to give you a sense of what is possible), we can look at the frequency with which particular word classes precede particular words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33f3dd11",
      "metadata": {
        "id": "33f3dd11"
      },
      "outputs": [],
      "source": [
        "brown_tagged = brown.tagged_words(tagset='universal')\n",
        "tags = [b[1] for (a, b) in nltk.bigrams(brown_tagged) if a[0] == 'car']\n",
        "fd = nltk.FreqDist(tags)\n",
        "fd.tabulate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97364b39",
      "metadata": {
        "id": "97364b39"
      },
      "source": [
        "Or the frequency with which particular word classes precede other word classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9606fc8c",
      "metadata": {
        "id": "9606fc8c"
      },
      "outputs": [],
      "source": [
        "brown_tagged = brown.tagged_words(tagset='universal')\n",
        "word_tag_pairs = nltk.bigrams(brown_tagged)\n",
        "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
        "noun_preceders_fd = nltk.FreqDist(noun_preceders)\n",
        "[(wt,_) for (wt, _) in noun_preceders_fd.most_common()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39882a7b",
      "metadata": {
        "id": "39882a7b"
      },
      "source": [
        "And you can even search for particular constructional patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24260d86",
      "metadata": {
        "id": "24260d86"
      },
      "outputs": [],
      "source": [
        "for tagged_sent in brown.tagged_sents(categories=\"news\")[1:75]:\n",
        "    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(tagged_sent):\n",
        "        if (t1.startswith('V') and w2 == 'and' and t3.startswith('V')):\n",
        "            print(w1, w2, w3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c608cc7",
      "metadata": {
        "id": "7c608cc7"
      },
      "source": [
        "## Building an automatic tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e030b80",
      "metadata": {
        "id": "2e030b80"
      },
      "source": [
        "A very simple approach to automated tagging that actually works quite well is to find the most common tag for each word in a training corpus (as we did above) and just tag all occurences of each word with its most common tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b34b23",
      "metadata": {
        "id": "29b34b23"
      },
      "outputs": [],
      "source": [
        "brown_tagged_sents = brown.tagged_sents(tagset='universal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b57d2d2",
      "metadata": {
        "id": "2b57d2d2"
      },
      "outputs": [],
      "source": [
        "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03719751",
      "metadata": {
        "id": "03719751"
      },
      "outputs": [],
      "source": [
        "unigram_tagger.tag([\"the\",\"cat\",\"sat\",\"on\",\"the\",\"mat\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53540c9",
      "metadata": {
        "id": "d53540c9"
      },
      "source": [
        "We can formally evaluate this by splitting our data into a training set and a testing set. We obtain the by-word tag frequencies from the training set and evaluate by tagging the test set and comparing our predicted tags to the human tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2459c935",
      "metadata": {
        "id": "2459c935"
      },
      "outputs": [],
      "source": [
        "training_set_size = int(len(brown_tagged_sents) * 0.9)\n",
        "train_sents = brown_tagged_sents[:training_set_size]\n",
        "test_sents = brown_tagged_sents[training_set_size:]\n",
        "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
        "unigram_tagger.accuracy(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a8eb1c",
      "metadata": {
        "id": "29a8eb1c"
      },
      "source": [
        "### Regular expression based tagging\n",
        "\n",
        "As a next step we want to use a more intelligent way to deal with words we haven't seen before, but making use of their orthography and/or morphology. Write regular expressions to classify words in this way and see if you can improve performance. I've added one example rule to get you started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98cdfe3e",
      "metadata": {
        "id": "98cdfe3e"
      },
      "outputs": [],
      "source": [
        "patterns = [\n",
        "    (r'.*ing$', 'VERB'),\n",
        "      ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16873f4e",
      "metadata": {
        "id": "16873f4e"
      },
      "outputs": [],
      "source": [
        "t0 = nltk.DefaultTagger('NOUN')\n",
        "t1 = nltk.RegexpTagger(patterns, backoff=t0)\n",
        "t2 = nltk.UnigramTagger(train_sents, backoff=t1)\n",
        "t2.evaluate(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39fc9617",
      "metadata": {
        "id": "39fc9617"
      },
      "source": [
        "As with other classification tasks we can generate a confusion matrix to see where things are going right or wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631b8865",
      "metadata": {
        "id": "631b8865"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "predicted = [tag for sent in brown.sents(categories='editorial') for (word, tag) in t2.tag(sent)]\n",
        "true = [tag for (word, tag) in brown.tagged_words(categories='editorial',tagset=\"universal\")]\n",
        "cm=pd.DataFrame(confusion_matrix(predicted, true),index=list(set(predicted)),columns=list(set(predicted)))\n",
        "cm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Looking at the context"
      ],
      "metadata": {
        "id": "o3xO_L2jriQP"
      },
      "id": "o3xO_L2jriQP"
    },
    {
      "cell_type": "markdown",
      "id": "5ffc87c6",
      "metadata": {
        "id": "5ffc87c6"
      },
      "source": [
        "We want to improve this, and an obvious next step is to give the tag that is most frequent for this word when it follows the previous word. The problem is this doesn't do very well. Any idea why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6929606",
      "metadata": {
        "id": "d6929606"
      },
      "outputs": [],
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_sents)\n",
        "bigram_tagger.evaluate(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbf4f57",
      "metadata": {
        "id": "1cbf4f57"
      },
      "source": [
        "We can still make use of the bigram information by combining it with the unigram tagger via a process known as backing off - for each word we check whether we have seen that word and preceding word in our training data. If we have then we tag it with the most frequent tag for that word in that context. If we haven't seen it then we tag the word with its most frequent tag regardless of context. And if we haven't seen the word before we tag it as a noun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f85628",
      "metadata": {
        "id": "d4f85628"
      },
      "outputs": [],
      "source": [
        "t0 = nltk.DefaultTagger('NOUN')\n",
        "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
        "t2.evaluate(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e9b152",
      "metadata": {
        "id": "a5e9b152"
      },
      "source": [
        "### NLTK's Averaged Perceptron tagger\n",
        "\n",
        "NLTKs default prebuilt tagger uses a Perceptron just like that we have been using for other tasks on the module. For more information on this approach see here: https://explosion.ai/blog/part-of-speech-pos-tagger-in-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0936e1c4",
      "metadata": {
        "id": "0936e1c4"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120b641d",
      "metadata": {
        "id": "120b641d"
      },
      "source": [
        "It can be run straightforwardly like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8337ddd3",
      "metadata": {
        "id": "8337ddd3"
      },
      "outputs": [],
      "source": [
        "text = nltk.word_tokenize(\"And now for something completely different\")\n",
        "nltk.pos_tag(text, tagset=\"universal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08864b1d",
      "metadata": {
        "id": "08864b1d"
      },
      "source": [
        "### POS tagging in other languages\n",
        "\n",
        "POS taggers are available for a great many languages. A popular package called Spacy contains a number. Here, as an example, is a German tagger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43868f13",
      "metadata": {
        "id": "43868f13"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c260b97",
      "metadata": {
        "id": "9c260b97"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c39c35a",
      "metadata": {
        "id": "5c39c35a"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1c5f40",
      "metadata": {
        "id": "1e1c5f40"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('de_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4569f4c2",
      "metadata": {
        "id": "4569f4c2"
      },
      "outputs": [],
      "source": [
        "text = \"Das ist nicht gut.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487ceb42",
      "metadata": {
        "id": "487ceb42"
      },
      "outputs": [],
      "source": [
        "s1_t = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05894816",
      "metadata": {
        "id": "05894816"
      },
      "outputs": [],
      "source": [
        "for tk in s1_t:\n",
        "    print(tk.text, tk.tag_, tk.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqQ6hQEziFSp"
      },
      "source": [
        "### Chunking / Shallow Parsing\n",
        "\n",
        "Chunking involves grouping together words into elementary phrases. In its most common form it doesn't involve any hierachical structure.\n"
      ],
      "id": "yqQ6hQEziFSp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU7Nm8nxWtP3"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ],
      "id": "iU7Nm8nxWtP3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvmAzVJnh4It"
      },
      "outputs": [],
      "source": [
        "text = nltk.word_tokenize(\"I study Linguistics and Social Anthropology at the University of Manchester\")"
      ],
      "id": "PvmAzVJnh4It"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zDIdnUEWIFJ"
      },
      "outputs": [],
      "source": [
        "grammar = r\"\"\"\n",
        "  NP: {<DET|ADP>?<ADJ>*<NOUN>}\n",
        "      {<NOUN>+}\n",
        "\"\"\"\n",
        "sent=nltk.pos_tag(text,tagset=\"universal\")\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "cs = cp.parse(sent)\n",
        "print(cs)"
      ],
      "id": "5zDIdnUEWIFJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e53dKlaEg73e"
      },
      "source": [
        "Update the grammar so that it produces the following shallow parse: <br> <br>\n",
        "(S <br>\n",
        "  (NP I/PRON) <br>\n",
        "  study/VERB <br>\n",
        "  (NP Linguistics/NOUN and/CONJ Social/NOUN Anthropology/NOUN) <br>\n",
        "  at/ADP <br>\n",
        "  (NP the/DET University/NOUN of/ADP Manchester/NOUN)) <br>"
      ],
      "id": "e53dKlaEg73e"
    }
  ],
  "metadata": {
    "colab": {
      "name": "Week_9_Seminar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}