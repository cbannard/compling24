{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75a34b51",
      "metadata": {
        "id": "75a34b51"
      },
      "source": [
        "# LELA32052 Computational Linguistics Week 8\n",
        "\n",
        "This week we are going first to take a look at the challenge of machine translation.\n",
        "\n",
        "We'll look at German-to-English MT. Here is a set of sentences - the s stands for source and the t for target. Hopefully the translations here will be somewhat transparent to you. The only thing that might not be obvious is the use of \"ja\". This means \"yes\" in some context but is also use to mean something like \"certainly\". So \"das haus ist ja gros\" could be translated as \"the house is certainly big\" but because there isn't a perfect match from ja to certainly it tends to just be omitted in English translation as it is here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531b6fb8",
      "metadata": {
        "id": "531b6fb8"
      },
      "outputs": [],
      "source": [
        "s1='klein ist das haus '\n",
        "t1='the house is small '\n",
        "s2='das haus ist ja groß '\n",
        "t2='the house is big '\n",
        "s3='ja das buch ist klein '\n",
        "t3='yes the book is small '\n",
        "s4='das haus '\n",
        "t4='the house '\n",
        "s5='ein buch '\n",
        "t5='a book '"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8821fe71",
      "metadata": {
        "id": "8821fe71"
      },
      "source": [
        "We are going to use the now very familiar re.sub function to perform translation first.\n",
        "The g2e function takes German as input and should output English.\n",
        "\n",
        "Its translation is performed using a series of re.sub functions.\n",
        "\n",
        "First let's take a really naive approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0ec3e8",
      "metadata": {
        "id": "5c0ec3e8"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d636ae",
      "metadata": {
        "id": "a8d636ae"
      },
      "outputs": [],
      "source": [
        "def g2e(out):\n",
        "    re.UNICODE\n",
        "    out=re.sub(\"klein \",\"small \",out)\n",
        "    out=re.sub(\"ist \",\"is \",out)\n",
        "    out=re.sub(\"das \",\"the \",out)\n",
        "    out=re.sub(\"haus \",\"house \",out)\n",
        "    out=re.sub(\"groß \",\"big \",out)\n",
        "    out=re.sub(\"buch \",\"book \",out)\n",
        "    out=re.sub(\"ein \",\"a \",out)\n",
        "    out=re.sub(\"ja \",\"yes \",out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcec4156",
      "metadata": {
        "id": "dcec4156"
      },
      "outputs": [],
      "source": [
        "print(g2e(s1) + \"\\n\" + g2e(s2)  + \"\\n\" + g2e(s3)  + \"\\n\" + g2e(s4)  + \"\\n\" + g2e(s5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be71ba42",
      "metadata": {
        "id": "be71ba42"
      },
      "source": [
        "That didn't work well. Your job is to change the rules so that the function returns the correct translation.\n",
        "\n",
        "To make your job easier I have marked the part of speech using the following tags, based on what an automatic part of speech tagger would do (we'll look at these and how they work next week).\n",
        "\n",
        "ADJ : adjective\n",
        "AUX : auxiliary verb\n",
        "ART : article/determiner\n",
        "N : noun\n",
        "ADV : adverb\n",
        "\n",
        "You can make use of the tags by matching them and their associated words like this:\n",
        "\n",
        "[^ ]+_ART\n",
        "\n",
        "so if you wrote\n",
        "\n",
        "re.sub(\"([^ ]+)_ART\",\"\\\\\\1\",out)\n",
        "\n",
        "then it would return an article without its tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeea4275",
      "metadata": {
        "id": "aeea4275"
      },
      "outputs": [],
      "source": [
        "s1='klein_ADJ ist_AUX das_ART haus_N'\n",
        "t1='the house is small'\n",
        "s2='das_ART haus_N ist_AUX ja_ADV groß_ADJ '\n",
        "t2='the house is big '\n",
        "s3='ja_ADV das_ART buch_N ist_AUX klein_ADJ'\n",
        "t3='yes the book is small '\n",
        "s4='das_ART haus_N'\n",
        "t4='the house '\n",
        "s5='ein_ART buch_N'\n",
        "t5='a book '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4926ce86",
      "metadata": {
        "id": "4926ce86"
      },
      "outputs": [],
      "source": [
        "def g2e(out):\n",
        "    re.UNICODE\n",
        "    out=re.sub('klein_','small_',out)\n",
        "    out=re.sub('ist_','is_',out)\n",
        "    out=re.sub('das_','the_',out)\n",
        "    out=re.sub('haus_','house_',out)\n",
        "    out=re.sub('ja_','yes_',out)\n",
        "    out=re.sub('groß_','big_',out)\n",
        "    out=re.sub('buch_','book_',out)\n",
        "    out=re.sub('ein_','a_',out)\n",
        "\n",
        "    out = re.sub('([^ ]+)_ADJ ([^ ]+)_AUX ([^ ]+)_ART ([^ ]+)_N','\\\\3 \\\\4 \\\\2 \\\\1',out)\n",
        "    out = re.sub('([^ ]+)_AUX yes_ADV ([^ ]+)_ADJ','\\\\1 \\\\2', out)\n",
        "    out = re.sub(\"_[^ ]+\",\"\",out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "930e9316",
      "metadata": {
        "id": "930e9316"
      },
      "outputs": [],
      "source": [
        "print(g2e(s1) + \"\\n\" + g2e(s2)  + \"\\n\" + g2e(s3)  + \"\\n\" + g2e(s4)  + \"\\n\" + g2e(s5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ac2071",
      "metadata": {
        "id": "33ac2071"
      },
      "source": [
        "### Another sentence set to explore\n",
        "\n",
        "Update the below function to translate these sentence pairs in as few a set of rules as possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801eab4a",
      "metadata": {
        "id": "801eab4a"
      },
      "outputs": [],
      "source": [
        "s1=\"der_ART mann_N hat_AUX fußball_N gespielt_V\"\n",
        "t1=\"the man played football\"\n",
        "s2=\"der_ART mann_N spielt_V fußball_N\"\n",
        "t2=\"the man plays football\"\n",
        "s3=\"der_ART mann_N hat_AUX kartoffeln_N gekocht_V\"\n",
        "t3=\"the man cooked potatoes\"\n",
        "s4=\"der_ART mann_N kocht_V kartoffeln_N\"\n",
        "t4=\"the man cooks potatoes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4d37a3",
      "metadata": {
        "id": "0c4d37a3"
      },
      "outputs": [],
      "source": [
        "def g2e(out):\n",
        "    re.UNICODE\n",
        "\n",
        "    out=re.sub('hat_AUX ([^ ]+_N) (ge[^ ]+_V)','\\\\2 \\\\1',out)\n",
        "\n",
        "    out=re.sub('der_','the_',out)\n",
        "    out=re.sub('mann_','man_',out)\n",
        "    out=re.sub('fußball_','football_',out)\n",
        "    out=re.sub('gespielt_','played_',out)\n",
        "    out=re.sub('spielt_','plays_',out)\n",
        "    out=re.sub('gekocht_','cooked_',out)\n",
        "    out=re.sub('kocht_','cooks_',out)\n",
        "    out=re.sub('kartoffeln_','potatoes_',out)\n",
        "\n",
        "\n",
        "    out = re.sub(\"_[^ ]+\",\"\",out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b278a023",
      "metadata": {
        "id": "b278a023",
        "outputId": "4ab8d03b-38ed-4a5e-de6c-af624ee99f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the man played football\n",
            "the man plays football\n",
            "the man cooked potatoes\n",
            "the man cooks potatoes\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(g2e(s1) + \"\\n\" + g2e(s2)  + \"\\n\" + g2e(s3)  + \"\\n\" + g2e(s4)  + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22018ce3",
      "metadata": {
        "id": "22018ce3"
      },
      "source": [
        "And if you are really feeling brave, try accounting for these too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f87d30",
      "metadata": {
        "id": "12f87d30"
      },
      "outputs": [],
      "source": [
        "s5=\"der_ART mann_N spielt_V gerne_ADV fußball_N\"\n",
        "t5=\"the man likes playing football\"\n",
        "s6=\"der_ART mann_N hat_AUX gerne_ADV fußball_N gespielt_V\"\n",
        "t6=\"the man liked to play football\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38adec38",
      "metadata": {
        "id": "38adec38"
      },
      "outputs": [],
      "source": [
        "def g2e(out):\n",
        "    re.UNICODE\n",
        "\n",
        "    out=re.sub('hat_AUX ([^ ]+_N) (ge[^ ]+_V)','\\\\2 \\\\1',out)\n",
        "\n",
        "    out=re.sub('der_','the_',out)\n",
        "    out=re.sub('mann_','man_',out)\n",
        "    out=re.sub('fußball_','football_',out)\n",
        "    out=re.sub('gespielt_','played_',out)\n",
        "    out=re.sub('spielt_','plays_',out)\n",
        "    out=re.sub('gekocht_','cooked_',out)\n",
        "    out=re.sub('kocht_','cooks_',out)\n",
        "    out=re.sub('kartoffeln_','potatoes_',out)\n",
        "\n",
        "    out=re.sub('([^ ]+)s_V gerne_ADV ([^ ]+)_N','likes \\\\1ing \\\\2',out)\n",
        "    out=re.sub('hat_AUX gerne_ADV ([^ ]+)_N ([^ ]+)ed_V','liked to \\\\2 \\\\1',out)\n",
        "\n",
        "    out = re.sub(\"_[^ ]+\",\"\",out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80dbecea",
      "metadata": {
        "id": "80dbecea",
        "outputId": "d2fa195e-edd9-4341-fe80-7f0ae0f3d6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the man played football\n",
            "the man plays football\n",
            "the man cooked potatoes\n",
            "the man cooks potatoes\n",
            "the man likes playing football\n",
            "the man liked to play football\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(g2e(s1) + \"\\n\" + g2e(s2)  + \"\\n\" + g2e(s3)  + \"\\n\" + g2e(s4) + \"\\n\" + g2e(s5) + \"\\n\" + g2e(s6) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f08c4f44",
      "metadata": {
        "id": "f08c4f44"
      },
      "source": [
        "## Statistical machine translation\n",
        "\n",
        "We will look next at statistical machine translation. NLTK has some built in tools for this that we can make use of."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6f547d",
      "metadata": {
        "id": "7d6f547d"
      },
      "source": [
        "To make sure we have latest version of nltk let's install and then restart runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab5bb49",
      "metadata": {
        "id": "3ab5bb49"
      },
      "outputs": [],
      "source": [
        "!pip install --user -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090cf113",
      "metadata": {
        "id": "090cf113"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "from nltk import AlignedSent\n",
        "from nltk import IBMModel3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9f3b93",
      "metadata": {
        "id": "fd9f3b93"
      },
      "source": [
        "### Build a translation table\n",
        "\n",
        "We start by performing alignment and building a translation table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9210ad",
      "metadata": {
        "id": "1e9210ad"
      },
      "outputs": [],
      "source": [
        "s1='klein ist das haus'\n",
        "t1='the house is small'\n",
        "s2='das haus ist ja groß'\n",
        "t2='the house is big'\n",
        "s3='das buch ist klein'\n",
        "t3='the book is small'\n",
        "s4='das buch'\n",
        "t4='the book'\n",
        "s4='das house'\n",
        "t4='the house'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b3d8d8",
      "metadata": {
        "id": "c0b3d8d8"
      },
      "outputs": [],
      "source": [
        "parallel_corpus = []\n",
        "parallel_corpus.append(AlignedSent(nltk.word_tokenize(s1),nltk.word_tokenize(t1)))\n",
        "parallel_corpus.append(AlignedSent(nltk.word_tokenize(s2),nltk.word_tokenize(t2)))\n",
        "parallel_corpus.append(AlignedSent(nltk.word_tokenize(s3),nltk.word_tokenize(t3)))\n",
        "parallel_corpus.append(AlignedSent(nltk.word_tokenize(s4),nltk.word_tokenize(t4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452d82f9",
      "metadata": {
        "id": "452d82f9"
      },
      "outputs": [],
      "source": [
        "ibm3 = IBMModel3(parallel_corpus, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc992b0c",
      "metadata": {
        "id": "bc992b0c"
      },
      "outputs": [],
      "source": [
        "ibm3.translation_table['haus']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5507ea24",
      "metadata": {
        "id": "5507ea24"
      },
      "source": [
        "You can download and train on a larger aligned corpus by running this code (but beware it will take quite a while):\n",
        "\n",
        "import nltk <br>\n",
        "nltk.download('comtrans') <br>\n",
        "ende=comtrans.aligned_sents('alignment-de-en.txt') <br>\n",
        "ende_subset = ende[1:100] <br>\n",
        "ibm3 = IBMModel3(ende_subset, 2) <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fc1844",
      "metadata": {
        "id": "21fc1844"
      },
      "outputs": [],
      "source": [
        "phrase_table = nltk.translate.PhraseTable()\n",
        "for triple in ibm3.translation_table.items():\n",
        "      for i in triple[1].items():\n",
        "            phrase_table.add((triple[0],),(i[0],),math.log(i[1]))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be3b041",
      "metadata": {
        "id": "1be3b041"
      },
      "outputs": [],
      "source": [
        "phrase_table.translations_for(('ist',))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b30a798",
      "metadata": {
        "id": "3b30a798"
      },
      "source": [
        "### Build a probabilistic language model\n",
        "\n",
        "We will use the collected works of Jane Austen here, but in real systems you would want to use a larger and more representative corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058597ea",
      "metadata": {
        "id": "058597ea"
      },
      "outputs": [],
      "source": [
        "!wget https://www.gutenberg.org/files/31100/31100.txt\n",
        "f = open('31100.txt',\"r\",encoding='windows-1252')\n",
        "text = f.read()\n",
        "text = text + \"\\n\" + t1 + \"\\n\" + t2 + \"\\n\" + t3 + \"\\n\" + t4 + \"\\n\" + t5 + \"\\n\"\n",
        "tokenized_text = [list(map(str.lower, nltk.word_tokenize(sent)))\n",
        "                  for sent in nltk.sent_tokenize(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbdaed16",
      "metadata": {
        "id": "bbdaed16"
      },
      "outputs": [],
      "source": [
        "import nltk.lm.preprocessing\n",
        "n = 3\n",
        "train_data, padded_sents = nltk.lm.preprocessing.padded_everygram_pipeline(n, tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a72adcc",
      "metadata": {
        "id": "2a72adcc"
      },
      "outputs": [],
      "source": [
        "from nltk.lm import MLE\n",
        "model = MLE(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ed628b",
      "metadata": {
        "id": "e1ed628b"
      },
      "outputs": [],
      "source": [
        "model.fit(train_data, padded_sents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc7b4d0c",
      "metadata": {
        "id": "dc7b4d0c"
      },
      "outputs": [],
      "source": [
        "model.generate(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3eabe71",
      "metadata": {
        "id": "b3eabe71"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "language_prob = defaultdict(lambda: -99.0)\n",
        "for t in nltk.ngrams(nltk.word_tokenize(t1 + \" \" + t2 + \" \" + t3 + \" \" + t4),3):\n",
        "    if model.logscore(t[2],[t[0],t[1]]) < 0:\n",
        "        language_prob[t] = model.logscore(t[2],[t[0],t[1]])\n",
        "    else:\n",
        "        language_prob[t] = -999\n",
        "language_model = type('',(object,),{'probability_change': lambda self, context, phrase: language_prob[phrase], 'probability': lambda self, phrase: language_prob[phrase]})()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d9bfa5",
      "metadata": {
        "id": "12d9bfa5"
      },
      "outputs": [],
      "source": [
        "language_prob.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0ef040",
      "metadata": {
        "id": "8c0ef040"
      },
      "source": [
        "### Combine with translation model to perform decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f64445",
      "metadata": {
        "id": "60f64445"
      },
      "outputs": [],
      "source": [
        "stack_decoder = nltk.translate.StackDecoder(phrase_table, language_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04ae526",
      "metadata": {
        "id": "e04ae526"
      },
      "outputs": [],
      "source": [
        "stack_decoder.distortion_factor = 1\n",
        "stack_decoder.word_penalty = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea15c438",
      "metadata": {
        "id": "ea15c438"
      },
      "outputs": [],
      "source": [
        "stack_decoder.translate(nltk.word_tokenize(\"das haus ist groß\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4a0db8",
      "metadata": {
        "id": "7e4a0db8"
      },
      "outputs": [],
      "source": [
        "stack_decoder.translate(nltk.word_tokenize(\"klein ist das haus\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Week_8_Seminar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}